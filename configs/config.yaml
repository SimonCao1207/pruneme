model_path: huzama/Full-3.2-16L
model_name: Full-3.2-16L
num_layers: 16
dataset_name: wikitext 
revision: pico-epoch_0
batch_size: 16
max_length: 2048
device: cuda
prune_layer: 6
method : prune-one